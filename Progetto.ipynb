{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "979eba2c-cb7e-4636-b3f4-5712f2c90ed3",
   "metadata": {},
   "source": [
    "## Import e Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d138f55a-471a-474f-ab6b-87d4a68e6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import HeNormal\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignora un FutureWarning di Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "422e336c-9061-4ee0-bd08-3615548ba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result_to_csv(model_name, accuracy, file_name='results.csv'):\n",
    "    # Check if the file exists\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    \n",
    "    # If the file exists, read it into a DataFrame\n",
    "    if file_exists:\n",
    "        df = pd.read_csv(file_name)\n",
    "    else:\n",
    "        # If the file does not exist, create an empty DataFrame\n",
    "        df = pd.DataFrame(columns=['Model', 'Accuracy'])\n",
    "    \n",
    "    # Create a new DataFrame with the new result\n",
    "    new_data = pd.DataFrame([[model_name, accuracy]], columns=['Model', 'Accuracy'])\n",
    "    \n",
    "    # Concatenate the existing DataFrame with the new data\n",
    "    df = pd.concat([df, new_data], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c425ed5-feaa-4445-941c-8e54e6bc00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_accuracy_from_csv(model_name, csv_file_name='results.csv'):\n",
    "    try:\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(csv_file_name)\n",
    "\n",
    "        # Find the accuracy corresponding to the model name\n",
    "        accuracy = df.loc[df['Model'] == model_name, 'Accuracy'].values[0]\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{csv_file_name}' not found.\")\n",
    "        return None\n",
    "    except IndexError:\n",
    "        print(f\"Model '{model_name}' not found in file '{csv_file_name}'.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8be11a6-3c5e-441f-afa0-e5d60e122164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di GPU disponibili: 1\n",
      "Nome GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Controlla le GPU disponibili\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"Numero di GPU disponibili: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"Nome GPU: {gpu.name}\")\n",
    "else:\n",
    "    print(\"Nessuna GPU disponibile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0813e-c0cb-4069-9ce5-ccb31e81bb43",
   "metadata": {},
   "source": [
    "## Import e Pre-processamento Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cadfb557-a422-4fd4-819f-2f998328a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di immagini totale =  5232\n",
      "Numero di immagini nel testing set =  524\n"
     ]
    }
   ],
   "source": [
    "x = np.load(r\"C:\\Users\\filip\\Desktop\\Filippo\\Uni\\Magistrale\\ML\\pneumonia_images.npy\")\n",
    "y = np.load(r\"C:\\Users\\filip\\Desktop\\Filippo\\Uni\\Magistrale\\ML\\pneumonia_labels.npy\")\n",
    "\n",
    "#creazione dei vari dataset\n",
    "seed = 1999\n",
    "#separazione train e test set\n",
    "train_images, test_images = train_test_split(x, test_size=0.1, random_state=seed)\n",
    "train_labels, test_labels = train_test_split(y, test_size=0.1, random_state=seed)\n",
    "\n",
    "print(\"Numero di immagini totale = \", len(x))\n",
    "print(\"Numero di immagini nel testing set = \", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afa201aa-1e93-42b0-b3ba-c864905a274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di immagini nel training set =  3765\n",
      "Numero di immagini nel validation set =  943\n"
     ]
    }
   ],
   "source": [
    "# creazione validation set e train set con split 80/20 a favore del training set\n",
    "x_valid_images = train_images[3765:]/255. # normalizzazione\n",
    "x_valid_labels = train_labels[3765:]\n",
    "x_train_images = train_images[:3765]/255. # normalizzazione\n",
    "x_train_labels = train_labels[:3765]\n",
    "\n",
    "#normalizzazione test set\n",
    "test_images = test_images/255.\n",
    "\n",
    "print(\"Numero di immagini nel training set = \", len(x_train_images))\n",
    "print(\"Numero di immagini nel validation set = \", len(x_valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8b4b366-e10a-4964-ad4f-cf96c9c8d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAQ+klEQVR4nO3c3W+UdbcG4FVK22nLUEopBYOIINHExETPPDMx8S/wn/XQxENj1CPjR18gUKGgtZZ+TT9mn63k3dlJZ629nZedXNex9/ymzzwzN8+B98x4PB4HAETEpf/0GwDgzaEUAEhKAYCkFABISgGApBQASEoBgKQUAEiXJ/0Pb9++XX7x/f39cub169flTERE5//BGw6H5cyDBw/KmU8//bSc+eSTT8qZruvXr5czd+/eLWc2NjbKmYiIxcXFcub8/LycOTw8LGdGo1E5c3p6Ws5ERFy+PPHXNb148aKc+fbbb8uZ3377rZw5OjoqZyJ63/WDg4Ny5rvvvitnzs7OypmIiFevXpUznft1kmvuSQGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIEy9s3bt3r/zineGvS5d6PdXJdQbGOuNxg8GgnOmOhXXOOjk5KWd2dnbKma7O39QZxJvWuN1ff/1VzkRELCwslDOd0bTOUGTn96FzvSMiXr58Wc50BvGWl5fLme7vV+e3qDuseBFPCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECaeIXpnXfe+SffR5qfn2/lOuNVnbPm5ubKmbW1tXJmmtehM+LVGVrrjNRF9N5f56yzs7OpnNO5hyL+uQG0/25lZaWcuXr1ajlzfHxczkT0Pqc///yznPnkk0/Kmc6wXUTE7u5uObO/v9866yKeFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIE0/6bWxslF98NBqVM92VwRs3bpQz6+vr5cxwOCxnFhcXy5nBYFDOREQcHR2VM50V0o7OuuWbrrOS2rnvIiL29vbKmc76Zueczve2e4+//fbb5UxnPbjzve1+l7a2tsqZZ8+etc66iCcFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIE28YtUZlOqMQ3VGqCIi7ty5U86899575UznOnRG6o6Pj8uZiIgXL16UM50xs6WlpXJmfn6+nInoXfPOWZ3BvtPT03KmO5rWGar717/+Vc48efKknOncQ3fv3i1nIiIePHhQzty/f7+cefr0aTnT/Ww7w4Xd8dCLeFIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUA0sSLSoeHh+UXn52dLWdWV1fLmYiI27dvT+WszgDaX3/9Vc68fPmynImI+P3338uZzgjhysrKVM6J6I3bDYfD1llVnRG9rs6w4tbWVjnz/ffflzOd93bv3r1yJiJiNBqVMw8fPixnFhYWypnBYFDORExv9HESnhQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGANPEg3vn5efnFO6NpN27cKGciemNr+/v75UxnqO758+flzN7eXjkT0Rsh7Hy2nVGyzmhaRG90bjwelzMzMzPlTEfnM+rqDDh2Mq9evSpnuvdD5957/PhxOfPFF1+UM3Nzc+VMRO/3qzPYNwlPCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECaeBBvdXW1/OKdcbu1tbVyJiLi8uWJ/5S0u7tbzuzs7JQz0xoTjOiNmXXe3/z8fDnTGamL6A2ndYbJLl2q/xupM87WdXh4WM50/qbhcFjOdD6jzn0XEbG9vV3OHB8flzOdkb/u39QZfex8thO97j/yqgD8v6QUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgDTxtOi1a9fKLz4YDMqZzkJjRG+l8eeffy5nOmusnYXZFy9elDMRvXXVzufUuQ4zMzPlTERvebLzN3UcHByUM9331lkQfv/998uZxcXFcubRo0flTGfttKuzmvvNN9+UM19++WU5ExHx1ltvlTO//vpr66yLeFIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUA0sSrZoeHh+UX39jYKGe6/vzzz3Jmd3e3nJmfny9nFhYWypkrV66UMxG963D9+vVyZlrDexERS0tL5czs7Gw5Mx6Pp3JOZ0wwovc5LS8vlzN37twpZ27dulXO/Pjjj+VMRMQvv/xSznQG+05OTsqZ58+flzMRvcHRznDhJDwpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAGniZa6zs7Pyi3dG046Pj8uZiIgnT56UM9vb2+VMZ8zs6OionFlbWytnIiL++OOPcqYzmtYZtxsOh+VMRG/4qzNceHp6Ws7Mzc2VM+fn5+VMRO9vunr1ajmzvr5eznRGHzvjjRERm5ubUzmrM1K3s7NTzkT0fiu7vxEX8aQAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoApInX3TqDV52xsO5I1tOnT8uZvb29cubSpXqPds7pDgN23l9ncK4zbtcdxOvce53xuM7YYWfcbjwelzMRvWHF0WhUznSuw9LSUjlz8+bNciYi4u7du+VMZ+ywc+22trbKmYiI69evlzOdEb1JeFIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIE08h9hZuDw8PCxnXrx4Uc5ERBwcHJQznfXNzgppZ/F0f3+/nImIePfdd8uZtbW1cqaz0Ni53hG91c7Z2dlypvP+Oud0FlwjInZ3d8uZznewc48vLy+XM52104je96mzyPrVV1+VM5ubm+VMRG8l9b333muddRFPCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECaeGlscXGx/OJbW1vlzPb2djkTETE3N1fOXLlypZzpjLOdn5+XM93RtNu3b5cznUG8zv3QGVqL6F3zwWAwlXOmlYmIGI1G5Uznmncyne/f6upqORMRsbGxUc503t/Dhw/LmfF4XM5E9Eb+On/TJDwpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAGniZa7l5eXyi//222/lzB9//FHORPQG2jo6Y2ErKyvlzMLCQjkTETEcDqdyVmewrzuINzs7W8503l9nYKwzdtjVuX6d8b3O9e7o3uNXr14tZzpDdZ9++mk58/PPP5czEb3PqTuaeRFPCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECaeIWpM760u7tbzhweHpYzEb3BvtevX5czndG0ziBed+yqM2bWHaqrmpmZaeU616I7tjYN3fd2enr6f/xO/med+6EzODcYDMqZiN73qTOY2Rk73NzcLGciIkajUSv3T/CkAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKAKSJB/F++eWX8osfHR1NJRMRcXJyUs7cvHmznOkMV3WGAbv29vbKmbW1tXJmWiN6Eb1hsmmNx3Xuh8uXJ/7a/ZvOMGDnrM53cJqDbp1xu86163wvOu8tojcE+vLly9ZZF/GkAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECaeEKxs4LYWdLc398vZyIiNjc3y5mNjY1yprOsOhgMypnOMmhExHg8Lmc6i6LTWiHt6ry/zue0tLRUzkzz2k3rs+3er2+yzkrqBx980Dpre3u7nPn7779bZ13EkwIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQJh7E++GHH8ov3hkL64zURfRGvJaXl8uZ4XBYziwuLpYzh4eH5UxExNHRUTlzcnJSznSu9+XLE99u/6Yz8nd2dtY6q2phYaGc6Y7HdXKdTOfaTeu9dXOd+7Uzztn5fYiIePr0aTnz008/tc66iCcFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIE28UPbq1avyi9+4caOcWV1dLWciIubn58uZg4ODcubJkyflTGcQbzAYlDMREdvb2+VMZ8Sr8zl1PqOIiNnZ2XKmM5p2fHxcznR07oeI3vvrDMFNS3cQr/M3jUajqZzT/f2am5srZ3Z3d1tnXcSTAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJAmHsS7d+9e+cWfPXtWzjx9+rSciYi4cuVKOdMZoeqMZHXe2/r6ejkTEbG/v1/OLCwslDNra2vlTHcIrpur6ny2nVG3zn3XPWtaQ3Cd93bpUu/fpJ2BxM5Znb/p6OionImI2NnZKWc6I6WT8KQAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoApIkH8YbDYfnFT05OppKJiLhz50458+GHH5YzMzMz5czh4WE50x0Le/nyZTnTGUDrDO91xtkiesNkb/I5nWsXEXFwcFDO7O3tlTOd72DnHupkInr3Uffeq9ra2mrlHj16VM50Bkcn4UkBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgDTxSmpnQbKzQnrr1q1yJiLi448/LmcePnxYzly+PPElS7u7u+VMZxEzImJ7e7ucWVhYKGdWVlbKme7y67TWS7vvr6r72XbWdjsrqZ1zOoun3UXk169flzOdv+n4+Lic2dzcLGcietdidXW1ddZFPCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAaeJ1t/X19fKLf/TRR+VMZ6QuImJ+fr6c6Qxedbz11lvlzGAwaJ01NzdXzkxrNK2rM1TXGdHrnNPJdEYVI3p/02g0Kmc6n21n5G9/f7+ciegNTHbO+vrrr8uZx48flzMRvXtiaWmpddZFPCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAaeIVps8++6z84leuXClnOsN2ERGLi4vlzHA4bJ01DUdHR61cZ5js9PS0dVbVzMxMK9cZnevcR51zOqZ1TkRvaK3zvb127Vo50x0G7Hy2CwsL5Uzn9+HJkyflTETEDz/8UM48evSoddZFPCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAaeJFqs54VWf4qzsWNs2z3mTTug7n5+dTOed/k6uanZ2dyjndIcbRaFTOdD6n8XhcznSuXfdz7fwWzc3NlTOff/55OfP8+fNyJiLi/v375YxBPAD+cUoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASBPPDc7Pz5dfvLNM2FlAjHizF087S5Vdnc+p8/66n1PHtJZfp5XpfC8iIpaWlsqZaa3Zdu6HaX4vOu9vY2NjKpmIiPX19XLmnXfeaZ11kTf3lxSAqVMKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoApH90EK8zQjU7O1vOdM/qmOaIV8e0xsxOT0/Lme5o4bTuo2ndQ2dnZ1M5J6L3N00r07mHurlOZmdnp5zp/j50RhJXVlZaZ13EkwIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQZsbj8fg//SYAeDN4UgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIP0XP3fdiifgE0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label immagine visualizzata:  [1]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train_images[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(\"Label immagine visualizzata: \", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd66c23-19fd-4528-b6e3-d49b98d10016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conta le occorrenze di ciascuna etichetta\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "labels_counts = dict(zip(unique, counts))\n",
    "\n",
    "# Crea il grafico a colonne\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels_counts.keys(), labels_counts.values(), color=['darkgreen', 'darkred'])\n",
    "\n",
    "# Imposta i titoli e le etichette\n",
    "ax.set_xlabel('Categoria')\n",
    "ax.set_ylabel('Numero di Occorrenze')\n",
    "ax.set_title('Distribuzione Esempi nel Dataset')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels(['0', '1'])\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058df044-f98e-4d08-81c9-d097d99cb057",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0e2c430-c005-45e3-ac11-f594acedb856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Validation set accuracy:  0.95864262990456\n",
      "Test set accuracy:  0.9599236641221374\n"
     ]
    }
   ],
   "source": [
    "x_train_flat = x_train_images.reshape(x_train_images.shape[0], -1)\n",
    "x_valid_flat = x_valid_images.reshape(x_valid_images.shape[0], -1)\n",
    "test_flat = test_images.reshape(test_images.shape[0], -1)\n",
    "\n",
    "# Creazione del modello di Random Forest\n",
    "rf = RandomForestClassifier(random_state=42) # seed per rendere l'esecuzione ripetibile\n",
    "\n",
    "# Definizione della griglia degli iperparametri\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'n_estimators': [200, 300, 500],\n",
    "    'max_depth': [None, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Creazione della grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=3)\n",
    "\n",
    "# Addestramento della grid search\n",
    "grid_search.fit(x_train_flat, x_train_labels.ravel()) # circa 10 minuti per la grid search\n",
    "\n",
    "# Migliori iperparametri trovati\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Valutazione del modello sul validation set\n",
    "best_rf = grid_search.best_estimator_\n",
    "valid_predictions = best_rf.predict(x_valid_flat)\n",
    "accuracy = accuracy_score(x_valid_labels.ravel(), valid_predictions)\n",
    "print(\"Validation set accuracy: \", accuracy)\n",
    "\n",
    "# Valutazione finale sul test set\n",
    "test_predictions = best_rf.predict(test_flat)\n",
    "test_accuracy_random_forest = accuracy_score(test_labels.ravel(), test_predictions)\n",
    "print(\"Test set accuracy: \", test_accuracy_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906864bd-49a2-4386-a83c-b1f54dec4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result_to_csv('Random Forest', test_accuracy_random_forest) # aggiunta entry per RF nel .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b09eb1-1491-4dd7-9efd-69a8b9d01d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       132\n",
      "           1       0.97      0.97      0.97       392\n",
      "\n",
      "    accuracy                           0.96       524\n",
      "   macro avg       0.95      0.95      0.95       524\n",
      "weighted avg       0.96      0.96      0.96       524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_test = classification_report(test_labels.ravel(), test_predictions)\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cbe55-cd72-4fa7-b660-c37d1358205b",
   "metadata": {},
   "source": [
    "## Regressione Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d280747-99b7-4d70-a29b-78f0a5423643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del modello di Logistic Regression\n",
    "# Utilizzando Pipeline per standardizzare i dati e applicare la regressione logistica\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardizzazione dei dati\n",
    "    ('logreg', LogisticRegression(random_state=42, max_iter=100))\n",
    "])\n",
    "\n",
    "# Definizione della griglia degli iperparametri per la regressione logistica\n",
    "param_grid_logreg = [\n",
    "    {'logreg__C': [0.01, 0.1, 1, 10, 100], # termine per la regolarizzazione. Più è piccolo più è forte \n",
    "     'logreg__solver': ['liblinear'],\n",
    "     'logreg__penalty': ['l1', 'l2']},\n",
    "    {'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "     'logreg__solver': ['saga'],\n",
    "     'logreg__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "     'logreg__l1_ratio': [0.5]},  # l1_ratio è richiesto per elasticnet\n",
    "    {'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "     'logreg__solver': ['newton-cg', 'lbfgs', 'sag', 'newton-cholesky'],\n",
    "     'logreg__penalty': ['l2']}\n",
    "]\n",
    "# Creazione della grid search\n",
    "grid_search_logreg = GridSearchCV(estimator=pipe, param_grid=param_grid_logreg, cv=3, n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1fd7b05-9888-4d1a-87ee-59eb45c07451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "Best parameters found for Logistic Regression:  {'logreg__C': 0.1, 'logreg__penalty': 'l2', 'logreg__solver': 'sag'}\n",
      "Validation set accuracy for Logistic Regression:  0.9618239660657476\n",
      "Test set accuracy for Logistic Regression:  0.9675572519083969\n"
     ]
    }
   ],
   "source": [
    "# Addestramento della grid search\n",
    "grid_search_logreg.fit(x_train_flat, x_train_labels.ravel())\n",
    "\n",
    "# Migliori iperparametri trovati\n",
    "print(\"Best parameters found for Logistic Regression: \", grid_search_logreg.best_params_)\n",
    "\n",
    "# Valutazione del modello sul validation set\n",
    "best_logreg = grid_search_logreg.best_estimator_\n",
    "valid_predictions_logreg = best_logreg.predict(x_valid_flat)\n",
    "accuracy_logreg = accuracy_score(x_valid_labels.ravel(), valid_predictions_logreg)\n",
    "print(\"Validation set accuracy for Logistic Regression: \", accuracy_logreg)\n",
    "\n",
    "# Valutazione finale sul test set\n",
    "test_predictions_logreg = best_logreg.predict(test_flat)\n",
    "test_accuracy_logreg = accuracy_score(test_labels.ravel(), test_predictions_logreg)\n",
    "print(\"Test set accuracy for Logistic Regression: \", test_accuracy_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e3a4585-85a8-4301-a53f-b8de0ffd97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result_to_csv('Logistic Regression', test_accuracy_logreg) # aggiunta entry per RF nel .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d6c6935-aada-4e82-ac29-3eb904eb3972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       132\n",
      "           1       0.96      0.97      0.97       392\n",
      "\n",
      "    accuracy                           0.95       524\n",
      "   macro avg       0.93      0.93      0.93       524\n",
      "weighted avg       0.95      0.95      0.95       524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_test_logreg = classification_report(test_labels.ravel(), test_predictions_logreg)\n",
    "print(report_test_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988d450-7a05-4cd4-bbe2-f4088feeb657",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d98286-6031-4c04-a970-27d5fa0be744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 4s 12ms/step - loss: 0.5597 - accuracy: 0.7230 - val_loss: 0.4675 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.8610 - val_loss: 0.2169 - val_accuracy: 0.9102\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2147 - accuracy: 0.9100 - val_loss: 0.1959 - val_accuracy: 0.9237\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.9290 - val_loss: 0.1850 - val_accuracy: 0.9264\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9190 - val_loss: 0.1898 - val_accuracy: 0.9264\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1717 - accuracy: 0.9350 - val_loss: 0.2360 - val_accuracy: 0.8959\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9260 - val_loss: 0.1906 - val_accuracy: 0.9264\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 0.9320 - val_loss: 0.2106 - val_accuracy: 0.9059\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1856 - accuracy: 0.9310 - val_loss: 0.1731 - val_accuracy: 0.9345\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.9360 - val_loss: 0.1697 - val_accuracy: 0.9361\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1512 - accuracy: 0.9460 - val_loss: 0.1588 - val_accuracy: 0.9401\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.9370 - val_loss: 0.1598 - val_accuracy: 0.9409\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1473 - accuracy: 0.9440 - val_loss: 0.3188 - val_accuracy: 0.8919\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.9330 - val_loss: 0.1551 - val_accuracy: 0.9401\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1405 - accuracy: 0.9450 - val_loss: 0.1623 - val_accuracy: 0.9328\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9530 - val_loss: 0.1485 - val_accuracy: 0.9428\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1251 - accuracy: 0.9500 - val_loss: 0.1478 - val_accuracy: 0.9426\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9540 - val_loss: 0.1746 - val_accuracy: 0.9366\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1383 - accuracy: 0.9440 - val_loss: 0.1470 - val_accuracy: 0.9442\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9540 - val_loss: 0.1486 - val_accuracy: 0.9412\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9360 - val_loss: 0.1886 - val_accuracy: 0.9167\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9470 - val_loss: 0.1539 - val_accuracy: 0.9372\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9440 - val_loss: 0.1451 - val_accuracy: 0.9436\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9570 - val_loss: 0.1401 - val_accuracy: 0.9469\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9530 - val_loss: 0.1701 - val_accuracy: 0.9288\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 0.9570 - val_loss: 0.1326 - val_accuracy: 0.9523\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9620 - val_loss: 0.1511 - val_accuracy: 0.9393\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9520 - val_loss: 0.1325 - val_accuracy: 0.9506\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0935 - accuracy: 0.9670 - val_loss: 0.1327 - val_accuracy: 0.9504\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9620 - val_loss: 0.1652 - val_accuracy: 0.9447\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9660 - val_loss: 0.1323 - val_accuracy: 0.9498\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0850 - accuracy: 0.9660 - val_loss: 0.1256 - val_accuracy: 0.9531\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.1822 - val_accuracy: 0.9350\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9680 - val_loss: 0.1326 - val_accuracy: 0.9517\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9740 - val_loss: 0.1739 - val_accuracy: 0.9266\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9710 - val_loss: 0.1345 - val_accuracy: 0.9504\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9700 - val_loss: 0.1276 - val_accuracy: 0.9506\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9790 - val_loss: 0.1322 - val_accuracy: 0.9523\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9790 - val_loss: 0.1333 - val_accuracy: 0.9531\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.9760 - val_loss: 0.1605 - val_accuracy: 0.9417\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 0.9690 - val_loss: 0.1406 - val_accuracy: 0.9528\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9780 - val_loss: 0.2756 - val_accuracy: 0.9172\n"
     ]
    }
   ],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "x_reshaped_train = x_train_images.reshape(-1,28,28,1)\n",
    "x_reshaped_valid = x_valid_images.reshape(-1,28,28,1)\n",
    "test_reshaped = test_images.reshape(-1,28,28,1)\n",
    "\n",
    "init = keras.initializers.HeNormal(seed=42)\n",
    "con_init = keras.initializers.GlorotUniform(seed=42)\n",
    "\n",
    "CNN_lenet = Sequential([\n",
    "    Conv2D(10, kernel_size=(5, 5), activation='relu',padding='same',input_shape=(28,28,1), kernel_initializer=con_init),\n",
    "    AveragePooling2D(pool_size=(2, 2),strides=2),\n",
    "    Conv2D(20, kernel_size=(5, 5), activation='relu', kernel_initializer=con_init),\n",
    "    AveragePooling2D(pool_size=(2, 2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_initializer=init),\n",
    "    Dense(128, activation='relu', kernel_initializer=init),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "CNN_lenet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_cnn_lenet = CNN_lenet.fit(x_reshaped_train, x_train_labels, epochs=300, validation_data=(x_reshaped_valid, x_valid_labels), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c1e8d5-0f35-4f68-a61c-befa8f1ef000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11366520076990128, 0.9541984796524048]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set\n",
    "CNN_lenet.evaluate(test_reshaped, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bd5cd3-d28b-45f3-ae7d-e2f490d97d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 10)        260       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 14, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 20)        5020      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               128256    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 166,561\n",
      "Trainable params: 166,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_lenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48290ce-3695-41b8-a3f6-db2d169f158d",
   "metadata": {},
   "source": [
    "## CNN + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e427b138-db3a-438a-a89d-4e651a035ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.6126 - accuracy: 0.6980 - val_loss: 0.5332 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.5633 - accuracy: 0.7280 - val_loss: 0.5177 - val_accuracy: 0.7449\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5072 - accuracy: 0.7390 - val_loss: 0.4013 - val_accuracy: 0.8371\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.3724 - accuracy: 0.8140 - val_loss: 0.2546 - val_accuracy: 0.9075\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.3103 - accuracy: 0.8690 - val_loss: 0.4999 - val_accuracy: 0.7195\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.2994 - accuracy: 0.8830 - val_loss: 0.2328 - val_accuracy: 0.8932\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2604 - accuracy: 0.8900 - val_loss: 0.2196 - val_accuracy: 0.9024\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2350 - accuracy: 0.9130 - val_loss: 0.1983 - val_accuracy: 0.9253\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2251 - accuracy: 0.9130 - val_loss: 0.1831 - val_accuracy: 0.9223\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2356 - accuracy: 0.9140 - val_loss: 0.1962 - val_accuracy: 0.9199\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2146 - accuracy: 0.9180 - val_loss: 0.1859 - val_accuracy: 0.9194\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1983 - accuracy: 0.9080 - val_loss: 0.1781 - val_accuracy: 0.9239\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2003 - accuracy: 0.9230 - val_loss: 0.1937 - val_accuracy: 0.9172\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1978 - accuracy: 0.9290 - val_loss: 0.1589 - val_accuracy: 0.9377\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1878 - accuracy: 0.9300 - val_loss: 0.1664 - val_accuracy: 0.9312\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1969 - accuracy: 0.9260 - val_loss: 0.1781 - val_accuracy: 0.9310\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.9250 - val_loss: 0.1518 - val_accuracy: 0.9396\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2012 - accuracy: 0.9210 - val_loss: 0.1722 - val_accuracy: 0.9377\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1989 - accuracy: 0.9290 - val_loss: 0.1500 - val_accuracy: 0.9401\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1865 - accuracy: 0.9320 - val_loss: 0.1610 - val_accuracy: 0.9337\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1794 - accuracy: 0.9340 - val_loss: 0.1444 - val_accuracy: 0.9453\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1595 - accuracy: 0.9360 - val_loss: 0.1536 - val_accuracy: 0.9404\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.9320 - val_loss: 0.1435 - val_accuracy: 0.9434\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1482 - accuracy: 0.9390 - val_loss: 0.1387 - val_accuracy: 0.9474\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9320 - val_loss: 0.1868 - val_accuracy: 0.9210\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1724 - accuracy: 0.9300 - val_loss: 0.1416 - val_accuracy: 0.9439\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1768 - accuracy: 0.9340 - val_loss: 0.1354 - val_accuracy: 0.9482\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1659 - accuracy: 0.9330 - val_loss: 0.1306 - val_accuracy: 0.9482\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 0.9410 - val_loss: 0.1339 - val_accuracy: 0.9482\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1420 - accuracy: 0.9380 - val_loss: 0.1324 - val_accuracy: 0.9480\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.9470 - val_loss: 0.1377 - val_accuracy: 0.9455\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1630 - accuracy: 0.9340 - val_loss: 0.1322 - val_accuracy: 0.9525\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1360 - accuracy: 0.9460 - val_loss: 0.1365 - val_accuracy: 0.9490\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1417 - accuracy: 0.9500 - val_loss: 0.1362 - val_accuracy: 0.9480\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1476 - accuracy: 0.9510 - val_loss: 0.1396 - val_accuracy: 0.9450\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9480 - val_loss: 0.1284 - val_accuracy: 0.9542\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1377 - accuracy: 0.9470 - val_loss: 0.1259 - val_accuracy: 0.9523\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1641 - accuracy: 0.9430 - val_loss: 0.1339 - val_accuracy: 0.9466\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1489 - accuracy: 0.9490 - val_loss: 0.1387 - val_accuracy: 0.9474\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1146 - accuracy: 0.9530 - val_loss: 0.1229 - val_accuracy: 0.9536\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9530 - val_loss: 0.1221 - val_accuracy: 0.9558\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1365 - accuracy: 0.9520 - val_loss: 0.1425 - val_accuracy: 0.9415\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1090 - accuracy: 0.9570 - val_loss: 0.1528 - val_accuracy: 0.9401\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1160 - accuracy: 0.9540 - val_loss: 0.1247 - val_accuracy: 0.9536\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1449 - accuracy: 0.9400 - val_loss: 0.1251 - val_accuracy: 0.9539\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1181 - accuracy: 0.9520 - val_loss: 0.1142 - val_accuracy: 0.9569\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1234 - accuracy: 0.9530 - val_loss: 0.1123 - val_accuracy: 0.9571\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1320 - accuracy: 0.9490 - val_loss: 0.1296 - val_accuracy: 0.9482\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1334 - accuracy: 0.9490 - val_loss: 0.1391 - val_accuracy: 0.9469\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1447 - accuracy: 0.9480 - val_loss: 0.1182 - val_accuracy: 0.9542\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1271 - accuracy: 0.9470 - val_loss: 0.1180 - val_accuracy: 0.9555\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1538 - accuracy: 0.9450 - val_loss: 0.1151 - val_accuracy: 0.9569\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1178 - accuracy: 0.9520 - val_loss: 0.1267 - val_accuracy: 0.9523\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1114 - accuracy: 0.9530 - val_loss: 0.1219 - val_accuracy: 0.9515\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.1158 - val_accuracy: 0.9523\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1189 - accuracy: 0.9590 - val_loss: 0.1189 - val_accuracy: 0.9523\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1082 - accuracy: 0.9580 - val_loss: 0.1394 - val_accuracy: 0.9436\n"
     ]
    }
   ],
   "source": [
    "x_reshaped_train = x_train_images.reshape(-1,28,28,1)\n",
    "x_reshaped_valid = x_valid_images.reshape(-1,28,28,1)\n",
    "test_reshaped = test_images.reshape(-1,28,28,1)\n",
    "\n",
    "init = keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "CNN_lenet_opt = Sequential([\n",
    "    Conv2D(10, kernel_size=(5, 5), activation='relu',padding='same',input_shape=(28,28,1)),\n",
    "    AveragePooling2D(pool_size=(2, 2),strides=2),        \n",
    "    Dropout(0.3),\n",
    "    Conv2D(20, kernel_size=(5, 5), activation='relu'),\n",
    "    AveragePooling2D(pool_size=(2, 2),strides=2),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_initializer=init),\n",
    "    Dropout(0.7),\n",
    "    Dense(128, activation='relu', kernel_initializer=init),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "CNN_lenet_opt.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_cnn_lenet = CNN_lenet_opt.fit(x_reshaped_train, x_train_labels, epochs=300, validation_data=(x_reshaped_valid, x_valid_labels), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feaa4458-94af-4c65-8498-1936225de114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09581366181373596, 0.9694656729698181]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set\n",
    "CNN_lenet_opt.evaluate(test_reshaped, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0da466-b39f-4ee8-a9b7-f326752aa2b4",
   "metadata": {},
   "source": [
    "### CNN + Dropout + Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06823d26-f8a8-4b2d-bf50-14e9550d24f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 2s 20ms/step - loss: 0.8006 - accuracy: 0.6100 - val_loss: 0.5761 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5111 - accuracy: 0.7710 - val_loss: 0.5228 - val_accuracy: 0.7449\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.3680 - accuracy: 0.8500 - val_loss: 0.5207 - val_accuracy: 0.7449\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.3091 - accuracy: 0.8670 - val_loss: 0.5205 - val_accuracy: 0.7449\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2810 - accuracy: 0.8890 - val_loss: 0.4868 - val_accuracy: 0.7449\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.2809 - accuracy: 0.8920 - val_loss: 0.4893 - val_accuracy: 0.7449\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2562 - accuracy: 0.9020 - val_loss: 0.6266 - val_accuracy: 0.7449\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.9040 - val_loss: 0.2933 - val_accuracy: 0.9253\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.2495 - accuracy: 0.9020 - val_loss: 0.2446 - val_accuracy: 0.9035\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2175 - accuracy: 0.9100 - val_loss: 0.4118 - val_accuracy: 0.7913\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2319 - accuracy: 0.9110 - val_loss: 0.2481 - val_accuracy: 0.8857\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.2157 - accuracy: 0.9080 - val_loss: 0.2041 - val_accuracy: 0.9320\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.2129 - accuracy: 0.9180 - val_loss: 0.2055 - val_accuracy: 0.9331\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9190 - val_loss: 0.1891 - val_accuracy: 0.9264\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.1803 - accuracy: 0.9310 - val_loss: 0.3399 - val_accuracy: 0.8301\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1873 - accuracy: 0.9240 - val_loss: 0.4640 - val_accuracy: 0.7476\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1693 - accuracy: 0.9310 - val_loss: 0.1712 - val_accuracy: 0.9328\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.2060 - accuracy: 0.9190 - val_loss: 0.4676 - val_accuracy: 0.7624\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1976 - accuracy: 0.9160 - val_loss: 0.1332 - val_accuracy: 0.9485\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1795 - accuracy: 0.9280 - val_loss: 0.3684 - val_accuracy: 0.8109\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9380 - val_loss: 0.6823 - val_accuracy: 0.6624\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1550 - accuracy: 0.9440 - val_loss: 0.2768 - val_accuracy: 0.8581\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1948 - accuracy: 0.9260 - val_loss: 0.1707 - val_accuracy: 0.9372\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.1645 - accuracy: 0.9420 - val_loss: 0.1628 - val_accuracy: 0.9355\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1554 - accuracy: 0.9370 - val_loss: 0.1235 - val_accuracy: 0.9547\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1496 - accuracy: 0.9530 - val_loss: 0.1784 - val_accuracy: 0.9221\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1583 - accuracy: 0.9410 - val_loss: 0.6625 - val_accuracy: 0.8441\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1452 - accuracy: 0.9480 - val_loss: 0.1896 - val_accuracy: 0.9250\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1635 - accuracy: 0.9370 - val_loss: 0.3135 - val_accuracy: 0.8436\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1590 - accuracy: 0.9430 - val_loss: 1.0714 - val_accuracy: 0.5200\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1582 - accuracy: 0.9400 - val_loss: 0.3264 - val_accuracy: 0.8840\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1405 - accuracy: 0.9460 - val_loss: 0.1183 - val_accuracy: 0.9552\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1694 - accuracy: 0.9320 - val_loss: 0.5472 - val_accuracy: 0.6958\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1407 - accuracy: 0.9530 - val_loss: 0.2284 - val_accuracy: 0.9199\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1517 - accuracy: 0.9440 - val_loss: 0.5319 - val_accuracy: 0.8409\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1519 - accuracy: 0.9370 - val_loss: 0.2000 - val_accuracy: 0.9272\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.9440 - val_loss: 2.0237 - val_accuracy: 0.2859\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 16ms/step - loss: 0.1375 - accuracy: 0.9500 - val_loss: 1.4250 - val_accuracy: 0.3716\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1695 - accuracy: 0.9400 - val_loss: 0.7161 - val_accuracy: 0.6386\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.1433 - accuracy: 0.9420 - val_loss: 0.1232 - val_accuracy: 0.9550\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 0.1444 - accuracy: 0.9420 - val_loss: 0.2811 - val_accuracy: 0.8762\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1270 - accuracy: 0.9530 - val_loss: 0.1520 - val_accuracy: 0.9447\n"
     ]
    }
   ],
   "source": [
    "# Reshape dei dati di input\n",
    "x_reshaped_train = x_train_images.reshape(-1, 28, 28, 1)\n",
    "x_reshaped_valid = x_valid_images.reshape(-1, 28, 28, 1)\n",
    "test_reshaped = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Inizializzazione dei pesi\n",
    "init = HeNormal(seed=42)\n",
    "\n",
    "# Costruzione della rete con batch normalization\n",
    "CNN_lenet_opt_bn = Sequential([\n",
    "    Conv2D(10, kernel_size=(5, 5), padding='same', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(20, kernel_size=(5, 5)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(256, kernel_initializer=init),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.7),\n",
    "\n",
    "    Dense(128, kernel_initializer=init),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.7),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Compilazione del modello\n",
    "CNN_lenet_opt_bn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Addestramento del modello\n",
    "history_cnn_lenet_bn = CNN_lenet_opt_bn.fit(x_reshaped_train, x_train_labels, epochs=300, validation_data=(x_reshaped_valid, x_valid_labels), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f74346c-32b0-4b21-8772-31912bfa498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10544075071811676, 0.9656488299369812]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set\n",
    "CNN_lenet_opt_bn.evaluate(test_reshaped, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92402a3-10a9-420d-ae03-7bd2724f340e",
   "metadata": {},
   "source": [
    "Mentre il dropout sembra aver migliorato leggermente l'accuracy, la Batch Normalization non sembra avere lo stesso effetto, avendo una accuracy sul testing set leggermente più bassa rispetto al modello precedente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e6c2e-2a6e-4361-a8d4-4a4843848ad9",
   "metadata": {},
   "source": [
    "## CNN con blocco Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824b516b-6c95-4666-bff8-9de5b8bcde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare un blocco Inception\n",
    "def single_inception_block(x, filters):\n",
    "    layers = tf.keras.layers\n",
    "    # Branch 1: 1x1 Convolution\n",
    "    branch1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Branch 2: 1x1 Convolution followed by 3x3 Convolution\n",
    "    branch2 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch2 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    # Branch 3: 1x1 Convolution followed by 5x5 Convolution\n",
    "    branch3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch3 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    # Branch 4: 3x3 MaxPooling followed by 1x1 Convolution\n",
    "    branch4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch4 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    output = layers.concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
    "    return output\n",
    "\n",
    "# Costruzione del modello\n",
    "def create_single_inception_cnn(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    \n",
    "    # blocco Inception\n",
    "    x = single_inception_block(inputs, 128)\n",
    "    \n",
    "    # Aggiunta di un Global Average Pooling per ridurre la dimensionalità\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Aggiunta di livelli densi per la classificazione\n",
    "    init = keras.initializers.HeNormal(seed=42)\n",
    "\n",
    "    x = layers.Dense(256, activation='relu', kernel_initializer=init)(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_initializer=init)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Creazione del modello con input shape (28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "CNN_single_inception = create_single_inception_cnn(input_shape)\n",
    "\n",
    "# Compilazione del modello\n",
    "CNN_single_inception.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Riassunto del modello\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69512ae4-340b-4cc0-9ced-587724cc89d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 3s 45ms/step - loss: 0.5861 - accuracy: 0.7290 - val_loss: 0.5622 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5841 - accuracy: 0.7290 - val_loss: 0.5697 - val_accuracy: 0.7449\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5880 - accuracy: 0.7290 - val_loss: 0.5725 - val_accuracy: 0.7449\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5868 - accuracy: 0.7290 - val_loss: 0.5598 - val_accuracy: 0.7449\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.5775 - accuracy: 0.7290 - val_loss: 0.5575 - val_accuracy: 0.7449\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5770 - accuracy: 0.7290 - val_loss: 0.5599 - val_accuracy: 0.7449\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5714 - accuracy: 0.7290 - val_loss: 0.5510 - val_accuracy: 0.7449\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.5725 - accuracy: 0.7290 - val_loss: 0.5634 - val_accuracy: 0.7449\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5658 - accuracy: 0.7290 - val_loss: 0.5952 - val_accuracy: 0.7449\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5684 - accuracy: 0.7290 - val_loss: 0.5401 - val_accuracy: 0.7449\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.5423 - accuracy: 0.7290 - val_loss: 0.5003 - val_accuracy: 0.7449\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.5027 - accuracy: 0.7510 - val_loss: 0.4821 - val_accuracy: 0.7524\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.4414 - accuracy: 0.8010 - val_loss: 0.3700 - val_accuracy: 0.8352\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3683 - accuracy: 0.8500 - val_loss: 0.3820 - val_accuracy: 0.8401\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.3470 - accuracy: 0.8480 - val_loss: 0.3170 - val_accuracy: 0.8614\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3232 - accuracy: 0.8560 - val_loss: 0.5379 - val_accuracy: 0.7352\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3831 - accuracy: 0.8250 - val_loss: 0.3270 - val_accuracy: 0.8581\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3092 - accuracy: 0.8780 - val_loss: 0.3051 - val_accuracy: 0.8587\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3068 - accuracy: 0.8660 - val_loss: 0.2965 - val_accuracy: 0.8676\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3219 - accuracy: 0.8690 - val_loss: 0.2963 - val_accuracy: 0.8638\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2951 - accuracy: 0.8710 - val_loss: 0.3187 - val_accuracy: 0.8536\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3491 - accuracy: 0.8450 - val_loss: 0.3080 - val_accuracy: 0.8617\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3243 - accuracy: 0.8500 - val_loss: 0.2913 - val_accuracy: 0.8692\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2919 - accuracy: 0.8760 - val_loss: 0.3181 - val_accuracy: 0.8560\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2878 - accuracy: 0.8800 - val_loss: 0.2835 - val_accuracy: 0.8684\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2954 - accuracy: 0.8760 - val_loss: 0.3636 - val_accuracy: 0.8363\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.3015 - accuracy: 0.8760 - val_loss: 0.2867 - val_accuracy: 0.8687\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3060 - accuracy: 0.8710 - val_loss: 0.2993 - val_accuracy: 0.8662\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3027 - accuracy: 0.8710 - val_loss: 0.3385 - val_accuracy: 0.8417\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.3016 - accuracy: 0.8820 - val_loss: 0.2801 - val_accuracy: 0.8689\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.3051 - accuracy: 0.8670 - val_loss: 0.3934 - val_accuracy: 0.8120\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2903 - accuracy: 0.8670 - val_loss: 0.2797 - val_accuracy: 0.8719\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2801 - accuracy: 0.8950 - val_loss: 0.2862 - val_accuracy: 0.8700\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.2717 - accuracy: 0.8790 - val_loss: 0.2729 - val_accuracy: 0.8722\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2844 - accuracy: 0.8810 - val_loss: 0.2832 - val_accuracy: 0.8762\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2680 - accuracy: 0.8900 - val_loss: 0.2719 - val_accuracy: 0.8800\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2800 - accuracy: 0.8840 - val_loss: 0.3013 - val_accuracy: 0.8689\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2704 - accuracy: 0.8890 - val_loss: 0.2905 - val_accuracy: 0.8687\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2776 - accuracy: 0.8720 - val_loss: 0.2975 - val_accuracy: 0.8741\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2716 - accuracy: 0.8920 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2982 - accuracy: 0.8710 - val_loss: 0.2666 - val_accuracy: 0.8800\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2703 - accuracy: 0.8900 - val_loss: 0.3053 - val_accuracy: 0.8635\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2738 - accuracy: 0.8880 - val_loss: 0.2923 - val_accuracy: 0.8703\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2683 - accuracy: 0.8990 - val_loss: 0.2931 - val_accuracy: 0.8681\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2525 - accuracy: 0.8990 - val_loss: 0.2555 - val_accuracy: 0.8902\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2541 - accuracy: 0.9020 - val_loss: 0.2677 - val_accuracy: 0.8859\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2680 - accuracy: 0.8920 - val_loss: 0.3097 - val_accuracy: 0.8557\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2782 - accuracy: 0.8870 - val_loss: 0.2958 - val_accuracy: 0.8660\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2528 - accuracy: 0.8960 - val_loss: 0.2564 - val_accuracy: 0.8900\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2435 - accuracy: 0.9100 - val_loss: 0.2463 - val_accuracy: 0.8943\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2512 - accuracy: 0.8990 - val_loss: 0.2470 - val_accuracy: 0.8929\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2688 - accuracy: 0.8870 - val_loss: 0.2450 - val_accuracy: 0.8929\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2439 - accuracy: 0.9080 - val_loss: 0.2740 - val_accuracy: 0.8789\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2453 - accuracy: 0.9000 - val_loss: 0.2439 - val_accuracy: 0.8946\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2667 - accuracy: 0.9030 - val_loss: 0.2611 - val_accuracy: 0.8843\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2401 - accuracy: 0.8930 - val_loss: 0.2420 - val_accuracy: 0.8999\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2624 - accuracy: 0.8950 - val_loss: 0.2680 - val_accuracy: 0.8838\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2383 - accuracy: 0.9070 - val_loss: 0.2605 - val_accuracy: 0.8816\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2420 - accuracy: 0.9050 - val_loss: 0.2302 - val_accuracy: 0.9061\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2245 - accuracy: 0.9090 - val_loss: 0.2278 - val_accuracy: 0.9061\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2412 - accuracy: 0.8960 - val_loss: 0.2848 - val_accuracy: 0.8708\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2263 - accuracy: 0.9070 - val_loss: 0.2455 - val_accuracy: 0.8972\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2411 - accuracy: 0.9060 - val_loss: 0.2501 - val_accuracy: 0.8873\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2262 - accuracy: 0.9010 - val_loss: 0.2182 - val_accuracy: 0.9121\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2511 - accuracy: 0.9010 - val_loss: 0.2275 - val_accuracy: 0.9078\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2304 - accuracy: 0.9120 - val_loss: 0.2506 - val_accuracy: 0.8886\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.2147 - accuracy: 0.9090 - val_loss: 0.2282 - val_accuracy: 0.9045\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2231 - accuracy: 0.9220 - val_loss: 0.2923 - val_accuracy: 0.8652\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2304 - accuracy: 0.9080 - val_loss: 0.2121 - val_accuracy: 0.9126\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2232 - accuracy: 0.9070 - val_loss: 0.2139 - val_accuracy: 0.9115\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.2071 - accuracy: 0.9180 - val_loss: 0.2058 - val_accuracy: 0.9180\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2090 - accuracy: 0.9130 - val_loss: 0.2225 - val_accuracy: 0.9045\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2196 - accuracy: 0.9100 - val_loss: 0.2028 - val_accuracy: 0.9194\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2150 - accuracy: 0.9030 - val_loss: 0.2501 - val_accuracy: 0.8983\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2219 - accuracy: 0.9120 - val_loss: 0.2010 - val_accuracy: 0.9226\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1969 - accuracy: 0.9200 - val_loss: 0.2021 - val_accuracy: 0.9186\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1922 - accuracy: 0.9260 - val_loss: 0.2033 - val_accuracy: 0.9177\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2073 - accuracy: 0.9150 - val_loss: 0.2484 - val_accuracy: 0.8854\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2251 - accuracy: 0.9040 - val_loss: 0.2192 - val_accuracy: 0.9110\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2004 - accuracy: 0.9150 - val_loss: 0.1974 - val_accuracy: 0.9194\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1894 - accuracy: 0.9280 - val_loss: 0.2352 - val_accuracy: 0.8932\n",
      "Epoch 82/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1877 - accuracy: 0.9330 - val_loss: 0.1875 - val_accuracy: 0.9258\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1905 - accuracy: 0.9250 - val_loss: 0.1898 - val_accuracy: 0.9215\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1794 - accuracy: 0.9310 - val_loss: 0.1774 - val_accuracy: 0.9318\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1784 - accuracy: 0.9330 - val_loss: 0.2450 - val_accuracy: 0.8875\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1906 - accuracy: 0.9220 - val_loss: 0.2273 - val_accuracy: 0.8983\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1853 - accuracy: 0.9240 - val_loss: 0.1790 - val_accuracy: 0.9285\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.2273 - accuracy: 0.9070 - val_loss: 0.2455 - val_accuracy: 0.9029\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1999 - accuracy: 0.9200 - val_loss: 0.1906 - val_accuracy: 0.9180\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1798 - accuracy: 0.9270 - val_loss: 0.1745 - val_accuracy: 0.9331\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1758 - accuracy: 0.9330 - val_loss: 0.1823 - val_accuracy: 0.9215\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1967 - accuracy: 0.9250 - val_loss: 0.1970 - val_accuracy: 0.9110\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1680 - accuracy: 0.9370 - val_loss: 0.1710 - val_accuracy: 0.9328\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1812 - accuracy: 0.9230 - val_loss: 0.2469 - val_accuracy: 0.9032\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.2002 - accuracy: 0.9210 - val_loss: 0.1700 - val_accuracy: 0.9342\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1685 - accuracy: 0.9360 - val_loss: 0.1724 - val_accuracy: 0.9323\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1613 - accuracy: 0.9390 - val_loss: 0.1655 - val_accuracy: 0.9393\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1734 - accuracy: 0.9280 - val_loss: 0.1878 - val_accuracy: 0.9296\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1606 - accuracy: 0.9350 - val_loss: 0.1639 - val_accuracy: 0.9396\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1650 - accuracy: 0.9330 - val_loss: 0.1706 - val_accuracy: 0.9331\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1712 - accuracy: 0.9330 - val_loss: 0.1751 - val_accuracy: 0.9382\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1721 - accuracy: 0.9310 - val_loss: 0.1669 - val_accuracy: 0.9369\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1657 - accuracy: 0.9350 - val_loss: 0.1989 - val_accuracy: 0.9097\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1687 - accuracy: 0.9340 - val_loss: 0.1638 - val_accuracy: 0.9361\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1568 - accuracy: 0.9340 - val_loss: 0.1847 - val_accuracy: 0.9339\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1547 - accuracy: 0.9360 - val_loss: 0.1586 - val_accuracy: 0.9382\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1859 - accuracy: 0.9250 - val_loss: 0.1642 - val_accuracy: 0.9358\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1589 - accuracy: 0.9340 - val_loss: 0.1822 - val_accuracy: 0.9361\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.1803 - accuracy: 0.9330 - val_loss: 0.2357 - val_accuracy: 0.9137\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.1656 - accuracy: 0.9300 - val_loss: 0.1724 - val_accuracy: 0.9328\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.1652 - accuracy: 0.9370 - val_loss: 0.1550 - val_accuracy: 0.9415\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1656 - accuracy: 0.9350 - val_loss: 0.1631 - val_accuracy: 0.9434\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1571 - accuracy: 0.9370 - val_loss: 0.2151 - val_accuracy: 0.9072\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 0.1652 - accuracy: 0.9310 - val_loss: 0.1617 - val_accuracy: 0.9380\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1463 - accuracy: 0.9400 - val_loss: 0.1628 - val_accuracy: 0.9436\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1681 - accuracy: 0.9260 - val_loss: 0.1769 - val_accuracy: 0.9345\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 0.1653 - val_accuracy: 0.9409\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1570 - accuracy: 0.9370 - val_loss: 0.1561 - val_accuracy: 0.9391\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.1537 - accuracy: 0.9380 - val_loss: 0.1906 - val_accuracy: 0.9355\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.1803 - accuracy: 0.9290 - val_loss: 0.2285 - val_accuracy: 0.8954\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.2028 - accuracy: 0.9260 - val_loss: 0.1734 - val_accuracy: 0.9248\n"
     ]
    }
   ],
   "source": [
    "# Creazione del callback EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Addestramento del modello\n",
    "history_single_inception = CNN_single_inception.fit(x_train_images, x_train_labels, epochs=300,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_valid_images, x_valid_labels),\n",
    "                    callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf51c0e-62b2-4049-82fd-5124c2b82cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1405 - accuracy: 0.9504\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 128)  256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 1)    0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 128)  256         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 128)  409728      conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 128)  256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 512)  0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 512)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          32896       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            129         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 722,689\n",
      "Trainable params: 722,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_single_inception.evaluate(test_images, test_labels)\n",
    "CNN_single_inception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4498b6-985d-4bae-9a1a-79df7da0ce57",
   "metadata": {},
   "source": [
    "L'idea è quella di costruire una CNN che richiami quella sviluppata da Google (GoogLeNet) andando a sfruttare il blocco transformer. Si opera questa scelta perché una rete del genere ha mostrato ottime prestazioni in passato, e per non dover cercare di ottimizzare il tipo di Pooling e la dimensione dei Kernel, andandone a sfruttare di diverse dimensioni all'interno del blocco Inception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "223fcb3f-1060-48ee-998e-39e03ba695de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare un blocco Inception\n",
    "def inception_module(x, filters):\n",
    "    layers = tf.keras.layers\n",
    "    # Branch 1: 1x1 Convolution\n",
    "    branch1 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # Branch 2: 1x1 Convolution followed by 3x3 Convolution\n",
    "    branch2 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch2 = layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    # Branch 3: 1x1 Convolution followed by 5x5 Convolution\n",
    "    branch3 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    branch3 = layers.Conv2D(filters, (5, 5), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    # Branch 4: 3x3 MaxPooling followed by 1x1 Convolution\n",
    "    branch4 = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch4 = layers.Conv2D(filters, (1, 1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    output = layers.concatenate([branch1, branch2, branch3, branch4], axis=-1)\n",
    "    return output\n",
    "\n",
    "# Costruzione del modello\n",
    "def create_inception_cnn(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    layers = tf.keras.layers\n",
    "\n",
    "    # Primo blocco Inception\n",
    "    x = inception_module(inputs, 32)\n",
    "\n",
    "    # Secondo blocco Inception\n",
    "    x = inception_module(x, 64)\n",
    "\n",
    "    # Terzo blocco Inception\n",
    "    x = inception_module(x, 128)\n",
    "\n",
    "    # Aggiunta di un Global Average Pooling per ridurre la dimensionalità\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Aggiunta di un livello denso per la classificazione\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Creazione del modello con input shape (28, 28, 1) per immagini in scala di grigi\n",
    "input_shape = (28, 28, 1)\n",
    "cnn_inception_extended = create_inception_cnn(input_shape)\n",
    "\n",
    "# Compilazione del modello\n",
    "cnn_inception_extended.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Riassunto del modello\n",
    "#cnn_inception_extended.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "538d97c0-6361-4e59-b813-36c6d3934075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 4s 68ms/step - loss: 0.6088 - accuracy: 0.7190 - val_loss: 0.5645 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.5958 - accuracy: 0.7290 - val_loss: 0.5606 - val_accuracy: 0.7449\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.5884 - accuracy: 0.7290 - val_loss: 0.5878 - val_accuracy: 0.7449\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.5421 - accuracy: 0.7290 - val_loss: 0.6724 - val_accuracy: 0.7505\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.5649 - accuracy: 0.7030 - val_loss: 0.4065 - val_accuracy: 0.7449\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.6022 - accuracy: 0.6980 - val_loss: 0.5879 - val_accuracy: 0.7449\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.6128 - accuracy: 0.7290 - val_loss: 0.6056 - val_accuracy: 0.7449\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.5875 - accuracy: 0.7290 - val_loss: 0.5375 - val_accuracy: 0.7449\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.5846 - accuracy: 0.7290 - val_loss: 0.5826 - val_accuracy: 0.7449\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.6047 - accuracy: 0.7290 - val_loss: 0.5727 - val_accuracy: 0.7449\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.5536 - accuracy: 0.7290 - val_loss: 0.5139 - val_accuracy: 0.7449\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.5783 - accuracy: 0.7060 - val_loss: 0.6081 - val_accuracy: 0.7449\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.5336 - accuracy: 0.7290 - val_loss: 0.6124 - val_accuracy: 0.7449\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.4894 - accuracy: 0.7290 - val_loss: 0.3810 - val_accuracy: 0.7451\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.4105 - accuracy: 0.7830 - val_loss: 0.4686 - val_accuracy: 0.6891\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.3913 - accuracy: 0.7900 - val_loss: 0.3259 - val_accuracy: 0.8522\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.4579 - accuracy: 0.7820 - val_loss: 0.3352 - val_accuracy: 0.8490\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.3616 - accuracy: 0.8490 - val_loss: 0.3122 - val_accuracy: 0.8627\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.3948 - accuracy: 0.8320 - val_loss: 0.3686 - val_accuracy: 0.8622\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.3180 - accuracy: 0.8760 - val_loss: 0.3194 - val_accuracy: 0.8401\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.3931 - accuracy: 0.8200 - val_loss: 0.3794 - val_accuracy: 0.8592\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.3481 - accuracy: 0.8380 - val_loss: 0.3189 - val_accuracy: 0.8662\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.3414 - accuracy: 0.8580 - val_loss: 0.3020 - val_accuracy: 0.8541\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.3256 - accuracy: 0.8540 - val_loss: 0.3057 - val_accuracy: 0.8603\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.3001 - accuracy: 0.8770 - val_loss: 0.4462 - val_accuracy: 0.7705\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.3287 - accuracy: 0.8530 - val_loss: 0.2837 - val_accuracy: 0.8765\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2992 - accuracy: 0.8750 - val_loss: 0.3044 - val_accuracy: 0.8538\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2770 - accuracy: 0.8850 - val_loss: 0.3145 - val_accuracy: 0.8724\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.3168 - accuracy: 0.8600 - val_loss: 0.2398 - val_accuracy: 0.8972\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2554 - accuracy: 0.8980 - val_loss: 0.2482 - val_accuracy: 0.8948\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2538 - accuracy: 0.8980 - val_loss: 0.1957 - val_accuracy: 0.9153\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1992 - accuracy: 0.9170 - val_loss: 0.2119 - val_accuracy: 0.9067\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2402 - accuracy: 0.9050 - val_loss: 0.1956 - val_accuracy: 0.9226\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.2491 - accuracy: 0.8930 - val_loss: 0.2335 - val_accuracy: 0.9032\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2081 - accuracy: 0.9160 - val_loss: 0.2246 - val_accuracy: 0.9008\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2217 - accuracy: 0.9110 - val_loss: 0.1756 - val_accuracy: 0.9261\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2127 - accuracy: 0.9170 - val_loss: 0.2011 - val_accuracy: 0.9215\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2191 - accuracy: 0.9170 - val_loss: 0.2775 - val_accuracy: 0.8808\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.2100 - accuracy: 0.9170 - val_loss: 0.1746 - val_accuracy: 0.9334\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1845 - accuracy: 0.9320 - val_loss: 0.1656 - val_accuracy: 0.9315\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1822 - accuracy: 0.9310 - val_loss: 0.2691 - val_accuracy: 0.8878\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1852 - accuracy: 0.9210 - val_loss: 0.1599 - val_accuracy: 0.9342\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1751 - accuracy: 0.9390 - val_loss: 0.1748 - val_accuracy: 0.9377\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1865 - accuracy: 0.9250 - val_loss: 0.1631 - val_accuracy: 0.9355\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.1486 - accuracy: 0.9470 - val_loss: 0.2927 - val_accuracy: 0.8660\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1682 - accuracy: 0.9320 - val_loss: 0.1732 - val_accuracy: 0.9277\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 2s 67ms/step - loss: 0.1986 - accuracy: 0.9190 - val_loss: 0.1598 - val_accuracy: 0.9382\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.1497 - accuracy: 0.9450 - val_loss: 0.1622 - val_accuracy: 0.9280\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.2290 - val_accuracy: 0.9132\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1535 - accuracy: 0.9440 - val_loss: 0.3621 - val_accuracy: 0.8417\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1819 - accuracy: 0.9240 - val_loss: 0.3136 - val_accuracy: 0.8503\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1751 - accuracy: 0.9340 - val_loss: 0.2855 - val_accuracy: 0.8727\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.2157 - accuracy: 0.9220 - val_loss: 0.1469 - val_accuracy: 0.9447\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1398 - accuracy: 0.9520 - val_loss: 0.1478 - val_accuracy: 0.9420\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1268 - accuracy: 0.9500 - val_loss: 0.1450 - val_accuracy: 0.9444\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1386 - accuracy: 0.9550 - val_loss: 0.1868 - val_accuracy: 0.9229\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1668 - accuracy: 0.9340 - val_loss: 0.1356 - val_accuracy: 0.9515\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1247 - accuracy: 0.9560 - val_loss: 0.2056 - val_accuracy: 0.9188\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1435 - accuracy: 0.9460 - val_loss: 0.2284 - val_accuracy: 0.9175\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1647 - accuracy: 0.9340 - val_loss: 0.1611 - val_accuracy: 0.9334\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1124 - accuracy: 0.9580 - val_loss: 0.1319 - val_accuracy: 0.9496\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1099 - accuracy: 0.9610 - val_loss: 0.1727 - val_accuracy: 0.9401\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1016 - accuracy: 0.9610 - val_loss: 0.1370 - val_accuracy: 0.9466\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1382 - accuracy: 0.9480 - val_loss: 0.1276 - val_accuracy: 0.9512\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.0858 - accuracy: 0.9660 - val_loss: 0.1425 - val_accuracy: 0.9520\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.0949 - accuracy: 0.9690 - val_loss: 0.1413 - val_accuracy: 0.9517\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0956 - accuracy: 0.9650 - val_loss: 0.1829 - val_accuracy: 0.9328\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1387 - accuracy: 0.9530 - val_loss: 0.1624 - val_accuracy: 0.9302\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0960 - accuracy: 0.9640 - val_loss: 0.1252 - val_accuracy: 0.9506\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 0.1957 - val_accuracy: 0.9275\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.1011 - accuracy: 0.9610 - val_loss: 0.1813 - val_accuracy: 0.9396\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 0.1079 - accuracy: 0.9690 - val_loss: 0.1352 - val_accuracy: 0.9509\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.0816 - accuracy: 0.9740 - val_loss: 0.1566 - val_accuracy: 0.9428\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0793 - accuracy: 0.9680 - val_loss: 0.1301 - val_accuracy: 0.9536\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.0728 - accuracy: 0.9750 - val_loss: 0.1407 - val_accuracy: 0.9512\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0779 - accuracy: 0.9740 - val_loss: 0.1820 - val_accuracy: 0.9417\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.1067 - accuracy: 0.9660 - val_loss: 0.2035 - val_accuracy: 0.9275\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0892 - accuracy: 0.9710 - val_loss: 0.1261 - val_accuracy: 0.9544\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 2s 61ms/step - loss: 0.0793 - accuracy: 0.9700 - val_loss: 0.1498 - val_accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "# Creazione del callback EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Addestramento del modello\n",
    "history = cnn_inception_extended.fit(x_train_images, x_train_labels, epochs=300,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_valid_images, x_valid_labels),\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "992e0ed7-3145-49be-b443-d207088cbd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1561 - accuracy: 0.9447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15605896711349487, 0.944656491279602]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_inception_extended.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c79fd-4c7b-4a7e-a16d-8dd665f183d3",
   "metadata": {},
   "source": [
    "Best: 0.9695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece2ed8-e67d-4f0b-b288-ee98e4f29f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione della struttura del modello\n",
    "plot_model(cnn_inception_extended, to_file='model_structure.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Mostra l'immagine della struttura del modello\n",
    "img = plt.imread('model_structure.png')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adb0b47-98bf-4ac6-90bd-c1bfb8497635",
   "metadata": {},
   "source": [
    "## Data Augmentation sul miglior modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3ac1288-1449-480c-9f4b-8d4acfdb1042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "31/31 [==============================] - 4s 69ms/step - loss: 0.5975 - accuracy: 0.7293 - val_loss: 0.6042 - val_accuracy: 0.7449\n",
      "Epoch 2/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.5889 - accuracy: 0.7293 - val_loss: 0.6072 - val_accuracy: 0.7449\n",
      "Epoch 3/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.5953 - accuracy: 0.7314 - val_loss: 0.5698 - val_accuracy: 0.7449\n",
      "Epoch 4/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.5894 - accuracy: 0.7324 - val_loss: 0.5726 - val_accuracy: 0.7449\n",
      "Epoch 5/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.5844 - accuracy: 0.7293 - val_loss: 0.5452 - val_accuracy: 0.7449\n",
      "Epoch 6/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.5446 - accuracy: 0.7314 - val_loss: 0.4651 - val_accuracy: 0.7754\n",
      "Epoch 7/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.5184 - accuracy: 0.7490 - val_loss: 0.4240 - val_accuracy: 0.8031\n",
      "Epoch 8/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.4637 - accuracy: 0.7800 - val_loss: 0.6971 - val_accuracy: 0.4725\n",
      "Epoch 9/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.4507 - accuracy: 0.7872 - val_loss: 0.3337 - val_accuracy: 0.8492\n",
      "Epoch 10/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3994 - accuracy: 0.8089 - val_loss: 0.5390 - val_accuracy: 0.6667\n",
      "Epoch 11/300\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.3264 - val_accuracy: 0.8563\n",
      "Epoch 12/300\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.3559 - accuracy: 0.8512 - val_loss: 0.3237 - val_accuracy: 0.8587\n",
      "Epoch 13/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.4151 - accuracy: 0.8068 - val_loss: 0.3470 - val_accuracy: 0.8541\n",
      "Epoch 14/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.3778 - accuracy: 0.8481 - val_loss: 0.3701 - val_accuracy: 0.8433\n",
      "Epoch 15/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.3448 - accuracy: 0.8481 - val_loss: 0.3545 - val_accuracy: 0.8045\n",
      "Epoch 16/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3199 - accuracy: 0.8709 - val_loss: 0.2690 - val_accuracy: 0.8749\n",
      "Epoch 17/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3099 - accuracy: 0.8760 - val_loss: 0.3447 - val_accuracy: 0.8209\n",
      "Epoch 18/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2876 - accuracy: 0.8936 - val_loss: 0.5024 - val_accuracy: 0.7400\n",
      "Epoch 19/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3045 - accuracy: 0.8874 - val_loss: 0.2448 - val_accuracy: 0.8921\n",
      "Epoch 20/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2553 - accuracy: 0.9081 - val_loss: 0.2158 - val_accuracy: 0.9080\n",
      "Epoch 21/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2530 - accuracy: 0.9091 - val_loss: 0.2014 - val_accuracy: 0.9134\n",
      "Epoch 22/300\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.2448 - accuracy: 0.9019 - val_loss: 0.2277 - val_accuracy: 0.9013\n",
      "Epoch 23/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2231 - accuracy: 0.9153 - val_loss: 0.2065 - val_accuracy: 0.9150\n",
      "Epoch 24/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.2364 - accuracy: 0.9081 - val_loss: 0.1879 - val_accuracy: 0.9248\n",
      "Epoch 25/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2391 - accuracy: 0.9039 - val_loss: 0.2208 - val_accuracy: 0.9140\n",
      "Epoch 26/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2430 - accuracy: 0.8998 - val_loss: 0.3329 - val_accuracy: 0.8487\n",
      "Epoch 27/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1954 - accuracy: 0.9225 - val_loss: 0.1781 - val_accuracy: 0.9315\n",
      "Epoch 28/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1897 - accuracy: 0.9287 - val_loss: 0.3718 - val_accuracy: 0.8376\n",
      "Epoch 29/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2039 - accuracy: 0.9225 - val_loss: 0.1857 - val_accuracy: 0.9261\n",
      "Epoch 30/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.1837 - accuracy: 0.9339 - val_loss: 0.2369 - val_accuracy: 0.8929\n",
      "Epoch 31/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.2112 - accuracy: 0.9184 - val_loss: 0.3245 - val_accuracy: 0.8560\n",
      "Epoch 32/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1830 - accuracy: 0.9277 - val_loss: 0.1412 - val_accuracy: 0.9415\n",
      "Epoch 33/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2269 - accuracy: 0.9070 - val_loss: 0.2671 - val_accuracy: 0.8916\n",
      "Epoch 34/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2420 - accuracy: 0.9019 - val_loss: 0.2023 - val_accuracy: 0.9150\n",
      "Epoch 35/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.1927 - accuracy: 0.9215 - val_loss: 0.1489 - val_accuracy: 0.9463\n",
      "Epoch 36/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2021 - accuracy: 0.9215 - val_loss: 0.1717 - val_accuracy: 0.9331\n",
      "Epoch 37/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1768 - accuracy: 0.9380 - val_loss: 0.1541 - val_accuracy: 0.9391\n",
      "Epoch 38/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1984 - accuracy: 0.9236 - val_loss: 0.1487 - val_accuracy: 0.9426\n",
      "Epoch 39/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1762 - accuracy: 0.9339 - val_loss: 0.1373 - val_accuracy: 0.9439\n",
      "Epoch 40/300\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.1713 - accuracy: 0.9298 - val_loss: 0.1286 - val_accuracy: 0.9490\n",
      "Epoch 41/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1495 - accuracy: 0.9432 - val_loss: 0.1352 - val_accuracy: 0.9450\n",
      "Epoch 42/300\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.1483 - accuracy: 0.9421 - val_loss: 0.2164 - val_accuracy: 0.9105\n",
      "Epoch 43/300\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.1668 - accuracy: 0.9339 - val_loss: 0.1558 - val_accuracy: 0.9369\n",
      "Epoch 44/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1833 - accuracy: 0.9318 - val_loss: 0.1463 - val_accuracy: 0.9431\n",
      "Epoch 45/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1682 - accuracy: 0.9360 - val_loss: 0.1433 - val_accuracy: 0.9442\n",
      "Epoch 46/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1711 - accuracy: 0.9390 - val_loss: 0.1999 - val_accuracy: 0.9094\n",
      "Epoch 47/300\n",
      "31/31 [==============================] - 2s 70ms/step - loss: 0.1523 - accuracy: 0.9401 - val_loss: 0.1523 - val_accuracy: 0.9358\n",
      "Epoch 48/300\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.1507 - accuracy: 0.9452 - val_loss: 0.1602 - val_accuracy: 0.9331\n",
      "Epoch 49/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.1445 - accuracy: 0.9380 - val_loss: 0.3045 - val_accuracy: 0.9134\n",
      "Epoch 50/300\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.2235 - accuracy: 0.9163 - val_loss: 0.2035 - val_accuracy: 0.9126\n"
     ]
    }
   ],
   "source": [
    "# Reshape dei dati di input\n",
    "x_reshaped_train = x_train_images.reshape(-1, 28, 28, 1)\n",
    "x_reshaped_valid = x_valid_images.reshape(-1, 28, 28, 1)\n",
    "test_reshaped = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Inizializzazione dei pesi\n",
    "init = HeNormal(seed=42)\n",
    "\n",
    "# Definizione della CNN\n",
    "input_shape = (28, 28, 1)\n",
    "cnn_inception_extended_da = create_inception_cnn(input_shape)\n",
    "\n",
    "# Compilazione del modello\n",
    "cnn_inception_extended_da.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Configurazione della Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0.05,  # no rotazione\n",
    "    width_shift_range=0.05,  # Spostamento casuale orizzontale del 10% della larghezza\n",
    "    height_shift_range=0.05,  # Spostamento casuale verticale del 10% dell'altezza\n",
    "    zoom_range=0.05,  # Zoom casuale del 10%\n",
    "    horizontal_flip=False,  # Ribaltamento casuale orizzontale\n",
    "    vertical_flip=False  # Senza ribaltamento casuale verticale\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Addestramento del modello con Data Augmentation\n",
    "history_cnn_inception_extended_da = cnn_inception_extended_da.fit(\n",
    "    datagen.flow(x_reshaped_train, x_train_labels, batch_size=32),\n",
    "    steps_per_epoch=len(x_reshaped_train) // 32,\n",
    "    epochs=300,\n",
    "    validation_data=(x_reshaped_valid, x_valid_labels),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57fb95f7-37c0-4c6a-a4b2-3509fbf06c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1086 - accuracy: 0.9599\n",
      "Test Loss: 0.10857484489679337\n",
      "Test Accuracy: 0.9599236845970154\n"
     ]
    }
   ],
   "source": [
    "# Valutazione del modello sui dati di test\n",
    "test_loss, test_accuracy = cnn_inception_extended_da.evaluate(test_reshaped, test_labels)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947672dc-be0a-478d-9183-ad5ae020b523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
